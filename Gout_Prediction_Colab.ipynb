{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac601be",
   "metadata": {},
   "source": [
    "\n",
    "# 🧬 Gout Disease Prediction (Google Colab Notebook)\n",
    "\n",
    "This Colab notebook trains and evaluates ML models to predict **gout** from a structured dataset (`dataset_gout_balanced.csv`).  \n",
    "It includes data loading (file upload or Google Drive), EDA, preprocessing, model training (Logistic Regression, Random Forest, XGBoost), evaluation, feature importance, and saving the best model.\n",
    "\n",
    "> **Expected target column:** `gout` (0/1).  \n",
    "> **Expected input:** numeric/categorical codes already encoded as numbers (as in NHANES-like data).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e22201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📦 Setup: Install packages (only needed once per runtime)\n",
    "# ============================================================\n",
    "!pip -q install xgboost==1.7.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📚 Imports & Config\n",
    "# ============================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📂 Data Loading\n",
    "# Options:\n",
    "#  1) Upload from your computer (choose a file dialog)\n",
    "#  2) Mount Google Drive and point to a path\n",
    "#  3) Use a file already in the Colab runtime (same folder)\n",
    "# ============================================================\n",
    "\n",
    "USE_UPLOAD = True   #@param {type:\"boolean\"}\n",
    "USE_DRIVE  = False  #@param {type:\"boolean\"}\n",
    "\n",
    "csv_path = \"dataset_gout_balanced.csv\"  #@param {type:\"string\"}\n",
    "\n",
    "if USE_UPLOAD:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()  # pick your CSV\n",
    "    if uploaded:\n",
    "        csv_path = list(uploaded.keys())[0]\n",
    "\n",
    "if USE_DRIVE and not USE_UPLOAD:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Example: csv_path = \"/content/drive/MyDrive/your_folder/dataset_gout_balanced.csv\"\n",
    "\n",
    "assert os.path.exists(csv_path), f\"CSV not found at: {csv_path}. Upload or set the correct path.\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"✅ Loaded:\", csv_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🔍 Quick EDA\n",
    "# ============================================================\n",
    "target_col = \"gout\"\n",
    "assert target_col in df.columns, f\"Target column '{target_col}' not found. Found: {df.columns.tolist()[:10]}...\"\n",
    "\n",
    "print(\"\\nColumns:\", len(df.columns))\n",
    "print(\"Dtypes:\\n\", df.dtypes.value_counts())\n",
    "print(\"\\nMissing values (top 20):\\n\", df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# Target distribution\n",
    "value_counts = df[target_col].value_counts(dropna=False).sort_index()\n",
    "print(\"\\nTarget distribution:\\n\", value_counts)\n",
    "\n",
    "plt.figure()\n",
    "value_counts.plot(kind='bar')\n",
    "plt.title(\"Target distribution (gout)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3872ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# ✂️ Train / Test split & preprocessing\n",
    "# ============================================================\n",
    "# Keep only numeric columns (assumes pre-encoded categories)\n",
    "numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c != target_col]\n",
    "X = df[numeric_cols].copy()\n",
    "y = df[target_col].astype(int).copy()\n",
    "\n",
    "print(f\"Using {len(numeric_cols)} numeric features:\", numeric_cols[:12], \"...\")\n",
    "\n",
    "# Simple imputation: fill missing with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[(\"num\", scaler, list(range(X_train.shape[1])))],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🤖 Define candidate models\n",
    "# ============================================================\n",
    "models = {\n",
    "    \"LogReg\": Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=200, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"prep\", \"passthrough\"),  # RF doesn't need scaling\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400, max_depth=None, min_samples_split=2,\n",
    "            n_jobs=-1, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"prep\", \"passthrough\"),  # trees don't need scaling\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=500, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.8,\n",
    "            reg_lambda=1.0, reg_alpha=0.0, objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "list(models.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🧪 Train & Evaluate all models\n",
    "# ============================================================\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted[name] = pipe\n",
    "\n",
    "    proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, zero_division=0)\n",
    "    roc = roc_auc_score(y_test, proba)\n",
    "    pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f} | F1: {f1:.4f} | ROC-AUC: {roc:.4f} | PR-AUC: {pr:.4f}\")\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, pred, zero_division=0))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "\n",
    "    results.append({\"model\": name, \"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc, \"pr_auc\": pr})\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(\"roc_auc\", ascending=False)\n",
    "print(\"\\n🏁 Summary (sorted by ROC-AUC):\")\n",
    "display(res_df.reset_index(drop=True))\n",
    "\n",
    "best_name = res_df.iloc[0][\"model\"]\n",
    "best_model = fitted[best_name]\n",
    "print(f\"\\nBest model: {best_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📈 ROC & Precision-Recall curves for the best model\n",
    "# ============================================================\n",
    "proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "pred_best = (proba_best >= 0.5).astype(int)\n",
    "\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, proba_best)\n",
    "plt.title(f\"ROC Curve – {best_name}\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "PrecisionRecallDisplay.from_predictions(y_test, proba_best)\n",
    "plt.title(f\"Precision-Recall Curve – {best_name}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🧩 Feature importance / coefficients\n",
    "# ============================================================\n",
    "def plot_top_importances(names, importances, top_k=20, title=\"Top Features\"):\n",
    "    idx = np.argsort(importances)[::-1][:top_k]\n",
    "    top_names = np.array(names)[idx]\n",
    "    top_vals  = np.array(importances)[idx]\n",
    "    plt.figure(figsize=(8, max(4, int(top_k/2))))\n",
    "    plt.barh(range(len(top_names))[::-1], top_vals[idx*0+0], align='center')  # keep default colors\n",
    "    plt.yticks(range(len(top_names))[::-1], top_names)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "if best_name == \"LogReg\":\n",
    "    # Coefficients after scaling\n",
    "    lr_final = best_model.named_steps[\"clf\"]\n",
    "    coefs = lr_final.coef_.ravel()\n",
    "    feat_names = [f\"z({c})\" for c in X_train.columns]\n",
    "    plot_top_importances(feat_names, np.abs(coefs), top_k=20, title=\"Top absolute coefficients (LogReg)\")\n",
    "\n",
    "else:\n",
    "    # RandomForest or XGBoost\n",
    "    clf = best_model.named_steps[\"clf\"]\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        importances = clf.feature_importances_\n",
    "        feat_names = X_train.columns\n",
    "        plot_top_importances(feat_names, importances, top_k=20, title=f\"Top importances ({best_name})\")\n",
    "    else:\n",
    "        print(\"No tree-based importances available for this model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862aeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 🔁 Cross-Validation (optional): ROC-AUC with 5-fold CV\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "if best_name == \"LogReg\":\n",
    "    model_for_cv = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=200, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "    ])\n",
    "elif best_name == \"RandomForest\":\n",
    "    model_for_cv = Pipeline([\n",
    "        (\"prep\", \"passthrough\"),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400, n_jobs=-1, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "else:\n",
    "    model_for_cv = Pipeline([\n",
    "        (\"prep\", \"passthrough\"),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=500, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.8,\n",
    "            eval_metric=\"logloss\", tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "cv_scores = cross_val_score(model_for_cv, X, y, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "print(\"CV ROC-AUC scores:\", cv_scores)\n",
    "print(\"CV ROC-AUC mean ± std:\", np.mean(cv_scores).round(4), \"±\", np.std(cv_scores).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 💾 Save the best model and example inference\n",
    "# ============================================================\n",
    "model_path = f\"best_gout_model_{best_name}.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(\"Saved model to:\", model_path)\n",
    "\n",
    "# Example: run inference on a single row from test set\n",
    "sample = X_test.iloc[[0]].copy()\n",
    "sample_pred_proba = best_model.predict_proba(sample)[:, 1][0]\n",
    "sample_pred = int(sample_pred_proba >= 0.5)\n",
    "print(\"\\nExample inference on one test row:\")\n",
    "print(\"Pred prob gout:\", round(sample_pred_proba, 4), \"| Pred label:\", sample_pred)\n",
    "\n",
    "# Template: how to predict on new data (replace with real values)\n",
    "template = X_train.median(numeric_only=True).to_frame().T  # use medians as placeholders\n",
    "template_pred = best_model.predict_proba(template)[:, 1][0]\n",
    "print(\"\\nTemplate input shape:\", template.shape, \"| Pred prob gout:\", round(template_pred, 4))\n",
    "template.to_csv(\"template_input.csv\", index=False)\n",
    "print(\"A CSV template (template_input.csv) with expected feature columns has been saved.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}